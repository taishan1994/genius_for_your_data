{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"BAAI/glm-10b\", trust_remote_code=True)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"BAAI/glm-10b\", trust_remote_code=True)\n",
    "model = model.half().cuda()\n",
    "\n",
    "inputs = tokenizer(\"machine learning [MASK] research interest [MASK]\", return_tensors=\"pt\")\n",
    "inputs = tokenizer.build_inputs_for_generation(inputs, max_gen_length=512, mask_id=tokenizer.mask_token_id)\n",
    "inputs = {key: value.cuda() for key, value in inputs.items()}\n",
    "inputs[\"generation_attention_mask\"] = inputs[\"generation_attention_mask\"].half()\n",
    "outputs = model.generate(**inputs, max_length=512, eos_token_id=tokenizer.eop_token_id, num_beams=4)\n",
    "print(tokenizer.decode(outputs[0].tolist()))\n",
    "# inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['position_ids'].shape, inputs['generation_attention_mask'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BertTokenizer, BartForConditionalGeneration, Text2TextGenerationPipeline\n",
    "# checkpoint = 'fnlp/bart-base-chinese'\n",
    "# tokenizer = BertTokenizer.from_pretrained(checkpoint)\n",
    "# sega_model = BartForConditionalGeneration.from_pretrained(checkpoint)\n",
    "# sega_generator = Text2TextGenerationPipeline(sega_model, tokenizer, device=0)\n",
    "# sega_generator\n",
    "# sega_generator = pipeline('text2text-generation', model='facebook/bart-large', device=0)\n",
    "sega_generator('<mask> interview <mask> The Associated Press<mask> Trump announced another White House run, Pence declined <mask> former president <mask>. But he <mask> positioned himself <mask> potential alternative <mask> Republicans <mask> conservative leadership <mask> Trump era.',max_length=200,num_beams=3,do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sega_generator.model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'<mask> Conference on Empirical Methods <mask> submission of research papers <mask> Deep Learning <mask>'\n",
    "'Bad news: <mask> the European Union <mask> month by EU <mask> Farm Commissioner Franz <mask>'\n",
    "\n",
    "ss = ['nice weekend movie fun',\n",
    "      'Shanghai food water help citizens virus',\n",
    "      'England ship China ocean Paris cake people',\n",
    "      'joint great food great drinks greater staff',\n",
    "      'Wuhan hot-dry noodel delicious breakfirst China street Hubuxiang tour nice place',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "# sega = pipeline(\"text2text-generation\",model='saved_models/bart-base-c4-realnewslike-4templates-passage-max15sents_2-sketch4/checkpoint-129375', framework='pt')\n",
    "s = '<mask> machine learning <mask> my research interest <mask> data science <mask>'\n",
    "sega(s, num_beams=3, do_sample=True, max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sega-chinese\n",
    "from transformers import BertTokenizer, BartForConditionalGeneration, Text2TextGenerationPipeline\n",
    "model_path = 'saved_models/bart-base-chinese-chinese_clean_passages_80m_with_sketch-10000000/checkpoint-93750'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "sega_model = BartForConditionalGeneration.from_pretrained(model_path)\n",
    "sega_generator = Text2TextGenerationPipeline(sega_model, tokenizer, device=7)\n",
    "\n",
    "bart_model = BartForConditionalGeneration.from_pretrained('fnlp/bart-base-chinese')\n",
    "bart_generator = Text2TextGenerationPipeline(bart_model, tokenizer, device=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_generator(\"今天[MASK]篮球[MASK]上海财经大学[MASK]\", max_length=50, do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sega_generator(\"今天[MASK]篮球[MASK]上海财经大学[MASK]\", max_length=50, do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sketchs = [\n",
    "    # \"今天[MASK]篮球[MASK]学校[MASK]\",\n",
    "    # \"自然语言处理[MASK]谷歌[MASK]通用人工智能[MASK]\",\n",
    "    # \"我昨天做了一个梦[MASK]又遇见了她[MASK]曾经那段时光让人怀恋[MASK]\",\n",
    "    \"[MASK]疫情[MASK]公园[MASK]散步[MASK]\",\n",
    "    # \"[MASK]酸菜鱼火锅[MASK]很美味，味道绝了[MASK]周末真开心[MASK]\"\n",
    "    \"\"\n",
    "]\n",
    "for sketch in sketchs:\n",
    "    print('input sketch:\\n>>> ', sketch)\n",
    "    print('BART-chinese output:\\n>>> ',bart_generator(sketch, max_length=100, do_sample=False)[0]['generated_text'].replace(' ',''))\n",
    "    print('SEGA-chinese output:\\n>>> ',sega_generator(sketch, max_length=100, do_sample=True, num_beams=3)[0]['generated_text'].replace(' ',''),'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('conda': virtualenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}